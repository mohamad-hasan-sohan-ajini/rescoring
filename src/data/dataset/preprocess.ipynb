{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0f423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4974a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_path = Path(\"validation\")\n",
    "test_path = Path(\"test\")\n",
    "train_path = Path(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414b2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb308dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 files.\n"
     ]
    }
   ],
   "source": [
    "removed = []\n",
    "for p in path.glob(\"*cleaned.txt\"):\n",
    "    try:\n",
    "        if p.is_file():\n",
    "            p.unlink()\n",
    "            removed.append(p)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to remove {p}: {e}\")\n",
    "\n",
    "print(f\"Removed {len(removed)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c79899c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28602"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(path.glob(\"*.txt\"))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff183f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "\n",
    "def _num_to_words_lt100(n: int) -> str:\n",
    "    \"\"\"0..99 -> written form (US/UK neutral, no hyphens).\"\"\"\n",
    "    ones = [\n",
    "        \"zero\",\n",
    "        \"one\",\n",
    "        \"two\",\n",
    "        \"three\",\n",
    "        \"four\",\n",
    "        \"five\",\n",
    "        \"six\",\n",
    "        \"seven\",\n",
    "        \"eight\",\n",
    "        \"nine\",\n",
    "        \"ten\",\n",
    "        \"eleven\",\n",
    "        \"twelve\",\n",
    "        \"thirteen\",\n",
    "        \"fourteen\",\n",
    "        \"fifteen\",\n",
    "        \"sixteen\",\n",
    "        \"seventeen\",\n",
    "        \"eighteen\",\n",
    "        \"nineteen\",\n",
    "    ]\n",
    "    tens = [\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"twenty\",\n",
    "        \"thirty\",\n",
    "        \"forty\",\n",
    "        \"fifty\",\n",
    "        \"sixty\",\n",
    "        \"seventy\",\n",
    "        \"eighty\",\n",
    "        \"ninety\",\n",
    "    ]\n",
    "\n",
    "    if 0 <= n < 20:\n",
    "        return ones[n]\n",
    "    t, o = divmod(n, 10)\n",
    "    return tens[t] if o == 0 else f\"{tens[t]} {ones[o]}\"\n",
    "\n",
    "\n",
    "def _strip_gutenberg_boilerplate(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Best-effort removal of Project Gutenberg header/footer.\n",
    "    If markers aren't found, returns the original text.\n",
    "    \"\"\"\n",
    "    # Common PG markers (case-insensitive)\n",
    "    start_pat = re.compile(\n",
    "        r\"\\*\\*\\*\\s*start of (this|the) project gutenberg\", re.IGNORECASE\n",
    "    )\n",
    "    end_pat = re.compile(r\"\\*\\*\\*\\s*end of (this|the) project gutenberg\", re.IGNORECASE)\n",
    "\n",
    "    start_m = start_pat.search(text)\n",
    "    end_m = end_pat.search(text)\n",
    "\n",
    "    if start_m:\n",
    "        # Skip the whole marker line\n",
    "        after_start = text.find(\"\\n\", start_m.start())\n",
    "        text = text[after_start + 1 if after_start != -1 else start_m.end() :]\n",
    "\n",
    "    if end_m:\n",
    "        text = text[: end_m.start()]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_gutenberg_txt(\n",
    "    load_path: Path,\n",
    "    save_path: Path,\n",
    "    min_words_per_paragraph: int = 32,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads a Project Gutenberg .txt file, cleans it, and writes the result.\n",
    "\n",
    "    Conditions implemented:\n",
    "      1) Drops paragraphs with fewer than `min_words_per_paragraph` words.\n",
    "      2) Removes punctuation except the single quote (').\n",
    "      3) Converts numbers < 100 into words; numbers >= 100 become <unk>.\n",
    "      4) Converts output to upper case (optionally keeping <unk> lower-case).\n",
    "\n",
    "    Output paragraphs are separated by a blank line.\n",
    "    \"\"\"\n",
    "    load_path = Path(load_path)\n",
    "    save_path = Path(save_path)\n",
    "\n",
    "    text = load_path.read_text(errors=\"ignore\")\n",
    "\n",
    "    text = _strip_gutenberg_boilerplate(text)\n",
    "\n",
    "    # Normalize newlines\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # Split into paragraphs (blank-line separated)\n",
    "    raw_paragraphs = re.split(r\"\\n\\s*\\n+\", text)\n",
    "\n",
    "    cleaned_paragraphs = []\n",
    "    num_pat = re.compile(r\"\\b\\d+\\b\")\n",
    "\n",
    "    for p in raw_paragraphs:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "\n",
    "        # Collapse internal whitespace\n",
    "        p = re.sub(r\"\\s+\", \" \", p)\n",
    "\n",
    "        # Convert numbers: <100 -> words, otherwise -> <unk>\n",
    "        def repl_num(m: re.Match) -> str:\n",
    "            n = int(m.group(0))\n",
    "            return _num_to_words_lt100(n) if n < 100 else UNK_TOKEN\n",
    "\n",
    "        p = num_pat.sub(repl_num, p)\n",
    "\n",
    "        # Remove punctuation except apostrophe:\n",
    "        # keep letters, digits, whitespace, and apostrophe. Replace everything else with space.\n",
    "        p = re.sub(r\"[^A-Za-z0-9\\s'<>]+\", \" \", p)\n",
    "        p = re.sub(r\"\\s+\", \" \", p).strip()\n",
    "\n",
    "        # Word-count filter\n",
    "        if len(p.split()) < min_words_per_paragraph:\n",
    "            continue\n",
    "\n",
    "        # Uppercase\n",
    "        p_up = p.upper()\n",
    "\n",
    "        # Optionally preserve <unk> as lowercase token\n",
    "        p_up = p_up.replace(UNK_TOKEN.upper(), UNK_TOKEN)\n",
    "\n",
    "        cleaned_paragraphs.append(p_up)\n",
    "\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    save_path.write_text(\n",
    "        \"\\n\\n\".join(cleaned_paragraphs) + (\"\\n\" if cleaned_paragraphs else \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a45482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28602/28602 [25:27<00:00, 18.73it/s] \n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    clean_gutenberg_txt(\n",
    "        file,\n",
    "        file.with_suffix(\".cleaned.txt\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7726941",
   "metadata": {},
   "source": [
    "# Concatenate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4552837",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'open'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m                         w.write(line.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mconcat_cleaned\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mconcat_cleaned\u001b[39m\u001b[34m(folder)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Match files that end exactly with \"cleaned.txt\"\u001b[39;00m\n\u001b[32m      6\u001b[39m files = \u001b[38;5;28msorted\u001b[39m([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m d.iterdir() \u001b[38;5;28;01mif\u001b[39;00m p.name.endswith(\u001b[33m\"\u001b[39m\u001b[33mcleaned.txt\u001b[39m\u001b[33m\"\u001b[39m)])\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m p.open(\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m r:\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'open'"
     ]
    }
   ],
   "source": [
    "def concat_cleaned(folder: str) -> Path:\n",
    "    d = Path(folder).expanduser().resolve()\n",
    "    out = Path(f\"{d.name}.txt\")\n",
    "\n",
    "    # Match files that end exactly with \"cleaned.txt\"\n",
    "    files = sorted([p for p in d.iterdir() if p.name.endswith(\"cleaned.txt\")])\n",
    "\n",
    "    with out.open(\"w\") as w:\n",
    "        for p in files:\n",
    "            with p.open(\"r\") as r:\n",
    "                for line in r:\n",
    "                    if line.strip():\n",
    "                        w.write(line.rstrip(\"\\n\") + \"\\n\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "concat_cleaned(Path(\"validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685c9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
